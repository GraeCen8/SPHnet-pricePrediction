{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4dbfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import accelerate as a \n",
    "\n",
    "#self made \n",
    "#import research as r\n",
    "from model import SPHNet\n",
    "from dataproccesing import process \n",
    "import dataproccesing as dp\n",
    "from training import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae48de4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m dataPARAMS = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfile_path\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdata/btc15m.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdate_column\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtest_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m,\n\u001b[32m      9\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m trainLoader, valLoader, testLoader, scaler, feature_columns = process(**dataPARAMS)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# infer number of features from the dataset (window samples shape = [N, seq_len, num_features])\u001b[39;00m\n\u001b[32m     13\u001b[39m num_features = trainLoader.dataset.X.shape[\u001b[32m2\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "\n",
    "dataPARAMS = {\n",
    "    \"file_path\": \"data/btc15m.csv\",\n",
    "    \"date_column\": \"timestamp\",\n",
    "    \"target_column\": \"close\",\n",
    "    \"window_size\": 256,\n",
    "    \"batch_size\": 128,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    }\n",
    "trainLoader, valLoader, testLoader, scaler, feature_columns = process(**dataPARAMS)\n",
    "\n",
    "# infer number of features from the dataset (window samples shape = [N, seq_len, num_features])\n",
    "num_features = trainLoader.dataset.X.shape[2]\n",
    "\n",
    "modelPARAMS = {\n",
    "    \"num_features\": num_features,\n",
    "    \"patch_size\": 8,\n",
    "    \"embed_dim\": 256,\n",
    "    \"vit_num_layers\": 4,\n",
    "    \"transformer_num_layers\": 4,\n",
    "    \"num_heads\": 8,\n",
    "    \"ff_dim\": 512,\n",
    "    \"dropout\": 0.4,\n",
    "    \"output_dim\": 1,\n",
    "}\n",
    "# make sure the class name matches what's defined in model.py\n",
    "model = SPHNet(**modelPARAMS)\n",
    "\n",
    "trainingPARAMS = {\n",
    "    \"valGAP\": 1,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"epochs\": 4,\n",
    "    \"model\": model,\n",
    "    \"optimizer\": torch.optim.Adam(model.parameters(), lr=1e-4),\n",
    "    \"trainLoader\": trainLoader,\n",
    "    \"valLoader\": valLoader,\n",
    "    \"testLoader\": testLoader,\n",
    "    \"scheduler\": StepLR(torch.optim.Adam(model.parameters(), lr=1e-4), step_size=10, gamma=0.1),\n",
    "    \"metrics\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1d045",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9f9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 /4 | Train Loss: 0.0018: 100%|██████████| 556/556 [00:29<00:00, 19.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.000502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 /4 | Train Loss: 0.0012: 100%|██████████| 556/556 [00:29<00:00, 19.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 0.000418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 /4 | Train Loss: 0.0010: 100%|██████████| 556/556 [00:28<00:00, 19.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 /4 | Train Loss: 0.0009: 100%|██████████| 556/556 [00:28<00:00, 19.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 0.000488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: 0.0001647191140896604\n"
     ]
    }
   ],
   "source": [
    "TrainedModel = Train(**trainingPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ad596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully into 'models/sphnet_model_1re.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(TrainedModel.state_dict(), 'models/sphnet_model_1re.pth')\n",
    "print(\"Model saved successfully into 'models/sphnet_model_1re.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa5da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86877a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(TrainedModel.state_dict(), 'models/sphnet_model_1re.pth')\n",
    "print(\"Model loaded successfully from 'models/sphnet_model_1re.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76550bf3",
   "metadata": {},
   "source": [
    "# testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e6870",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "based on the paper their are a few different tests that i can do\n",
    "\n",
    "for price prediction:\n",
    "    - r^2: a coefficient of dermination\n",
    "    - MSE: avg squared distance of prediction\n",
    "for direction prediction:\n",
    "    - precision: TP / TP + FP\n",
    "    - accuracy: (TP + FP) / (TP + FP + TN + FN)\n",
    "    - recall: TP / TP + FN\n",
    "TP, TN, FP, FN are defined as: (relative to A being up as a class)\n",
    "    - TP: y == A and y-hat == A\n",
    "    - TN: y != A and y-hat != A\n",
    "    - FP: y == A but y-hat != A\n",
    "    - FN: y != A but y-hat == A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3c71670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price based tests as defined above\n",
    "\n",
    "#testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc95310",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     idx = \u001b[43mfeature_columns\u001b[49m.index(\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'feature_columns' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m     idx = feature_columns.index(\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     idxs = [i \u001b[38;5;28;01mfor\u001b[39;00m i,c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mfeature_columns\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m c.lower()==\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     34\u001b[39m     idx = idxs[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m idxs \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse_target\u001b[39m(vec):\n",
      "\u001b[31mNameError\u001b[39m: name 'feature_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set (price metrics)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TrainedModel = TrainedModel.to(device)\n",
    "TrainedModel.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_last_close = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in testLoader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = TrainedModel(inputs)\n",
    "        preds = outputs.detach().cpu().numpy().reshape(-1)\n",
    "        targs = targets.detach().cpu().numpy().reshape(-1)\n",
    "        last_close = inputs.detach().cpu().numpy()[:, -1, :]\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(targs)\n",
    "        all_last_close.append(last_close)\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "all_last_close = np.concatenate(all_last_close)\n",
    "\n",
    "# inverse transform using scaler and feature_columns\n",
    "try:\n",
    "    idx = feature_columns.index('close')\n",
    "except Exception:\n",
    "    idxs = [i for i,c in enumerate(feature_columns) if c.lower()=='close']\n",
    "    idx = idxs[0] if idxs else 0\n",
    "\n",
    "def inverse_target(vec):\n",
    "    N = vec.shape[0]\n",
    "    tmp = np.zeros((N, len(feature_columns)))\n",
    "    tmp[:, idx] = vec\n",
    "    inv = scaler.inverse_transform(tmp)\n",
    "    return inv[:, idx]\n",
    "\n",
    "preds_orig = inverse_target(all_preds)\n",
    "targets_orig = inverse_target(all_targets)\n",
    "\n",
    "mse = mean_squared_error(targets_orig, preds_orig)\n",
    "r2 = r2_score(targets_orig, preds_orig)\n",
    "print(f\"Test MSE (orig scale): {mse:.6f}\")\n",
    "print(f\"Test R2 (orig scale): {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction metrics (compare predicted movement vs last observed close)\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "\n",
    "# last_close is array of shape (N, num_features), take idx column\n",
    "last_close_vals = all_last_close[:, idx]\n",
    "\n",
    "true_dir = (targets_orig > last_close_vals).astype(int)\n",
    "pred_dir = (preds_orig > last_close_vals).astype(int)\n",
    "\n",
    "precision = precision_score(true_dir, pred_dir, zero_division=0)\n",
    "accuracy = accuracy_score(true_dir, pred_dir)\n",
    "recall = recall_score(true_dir, pred_dir, zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83194946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: predicted vs true close and a few features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot first 200 samples\n",
    "n = min(200, len(preds_orig))\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(targets_orig[:n], label='True Close')\n",
    "plt.plot(preds_orig[:n], label='Predicted Close')\n",
    "plt.legend()\n",
    "plt.title('Predicted vs True Close (first samples)')\n",
    "plt.show()\n",
    "\n",
    "# plot selected feature series from test set (first window of first batch)\n",
    "inputs_batch, targets_batch = next(iter(testLoader))\n",
    "inputs_np = inputs_batch.numpy()\n",
    "Nplot = min(3, inputs_np.shape[0])\n",
    "feature_idx = idx\n",
    "plt.figure(figsize=(12,6))\n",
    "for i in range(Nplot):\n",
    "    series = inputs_np[i,:,feature_idx]\n",
    "    tmp = np.zeros((series.shape[0], len(feature_columns)))\n",
    "    tmp[:, feature_idx] = series\n",
    "    series_orig = scaler.inverse_transform(tmp)[:, feature_idx]\n",
    "    plt.plot(series_orig, label=f'series {i}')\n",
    "plt.title('Feature \"close\" over window (sample windows)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
