{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4dbfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import accelerate as a \n",
    "\n",
    "#self made \n",
    "#import research as r\n",
    "from model import SPHNet, SPHNetTest\n",
    "from dataproccesing import process \n",
    "import dataproccesing as dp\n",
    "from training import Train\n",
    "from ModelFuncs import eval_model_performance, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ae48de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grae/Coding projects/SPHnet-pricePrediction/dataproccesing.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[scale_cols]  = scaler.transform(test_df[scale_cols])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataPARAMS = {\n",
    "    \"file_path\": \"data/btc15m.csv\",\n",
    "    \"date_column\": \"timestamp\",\n",
    "    \"target_column\": \"logRet\",\n",
    "    \"window_size\": 256,\n",
    "    \"batch_size\": 128,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    }\n",
    "trainLoader, valLoader, testLoader, scaler, feature_columns = process(**dataPARAMS)\n",
    "\n",
    "# infer number of features from the dataset (window samples shape = [N, seq_len, num_features])\n",
    "num_features = trainLoader.dataset.X.shape[2]\n",
    "\n",
    "modelPARAMS = {\n",
    "        'num_features': 20,        \n",
    "        'patch_size': 8,             \n",
    "        'embed_dim': 256,            \n",
    "        'vit_num_layers': 6,         \n",
    "        'transformer_num_layers': 6, \n",
    "        'num_heads': 8,              \n",
    "        'ff_dim': 512,               \n",
    "        'dropout': 0.3,              \n",
    "        'output_dim': 1              \n",
    "}\n",
    "# make sure the class name matches what's defined in model.py\n",
    "model = SPHNetTest(**modelPARAMS)\n",
    "\n",
    "trainingPARAMS = {\n",
    "    \"valGAP\": 1,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"epochs\": 20,\n",
    "    \"model\": model,\n",
    "    \"optimizer\": torch.optim.Adam(model.parameters(), lr=1e-3),\n",
    "    \"trainLoader\": trainLoader,\n",
    "    \"valLoader\": valLoader,\n",
    "    \"testLoader\": testLoader,\n",
    "    \"scheduler\": StepLR(torch.optim.Adam(model.parameters(), lr=1e-3), step_size=10, gamma=0.1),\n",
    "    \"metrics\": None,\n",
    "}\n",
    "eval_model_performance\n",
    "evalPARAMS = {\n",
    "    'target_column': dataPARAMS['target_column'],\n",
    "    'feature_names': feature_columns,\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1d045",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce9f9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 /20 | Train Loss: 1.0131: 100%|██████████| 557/557 [04:10<00:00,  2.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m TrainedModel = \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrainingPARAMS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding projects/SPHnet-pricePrediction/training.py:56\u001b[39m, in \u001b[36mTrain\u001b[39m\u001b[34m(model, optimizer, trainLoader, valLoader, testLoader, scheduler, metrics, epochs, valGAP, criterion)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scheduler:\n\u001b[32m     54\u001b[39m         scheduler.step()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     train_losses.append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     57\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m     59\u001b[39m avg_train_loss = np.mean(train_losses) \u001b[38;5;28;01mif\u001b[39;00m train_losses \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "TrainedModel = Train(**trainingPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully into 'models/sphnet_model_1Fixed.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(TrainedModel.state_dict(), 'models/sphnet_model_v2.pth')\n",
    "print(\"Model saved successfully into 'models/sphnet_model_v2.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86877a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainedModel = SPHNet(**modelPARAMS)\n",
    "TrainedModel.load_state_dict(torch.load('models/sphnet_model_1re.pth'))\n",
    "print(\"Model loaded successfully from 'models/sphnet_model_1re.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76550bf3",
   "metadata": {},
   "source": [
    "# testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e6870",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "based on the paper their are a few different tests that i can do\n",
    "\n",
    "for price prediction:\n",
    "    - r^2: a coefficient of dermination\n",
    "    - MSE: avg squared distance of prediction\n",
    "for direction prediction:\n",
    "    - precision: TP / TP + FP\n",
    "    - accuracy: (TP + FP) / (TP + FP + TN + FN)\n",
    "    - recall: TP / TP + FN\n",
    "TP, TN, FP, FN are defined as: (relative to A being up as a class)\n",
    "    - TP: y == A and y-hat == A\n",
    "    - TN: y != A and y-hat != A\n",
    "    - FP: y == A but y-hat != A\n",
    "    - FN: y != A but y-hat == A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06799c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload modelFuncs with updated predict function\n",
    "from importlib import reload\n",
    "import ModelFuncs\n",
    "reload(ModelFuncs)\n",
    "from ModelFuncs import predict, eval_model_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c71670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': 'volume,logRet,absLogRet,velocity,range,logRange,signedLogRange,trueRange,emaTR,trRatio,emaAbsRet,volShock,volPersist,emaClose,emaDist,reversal,emaVol,volSurprise,volPriceInteraction', 'target': 'logRet', 'mse': 1.2942275134264491e-05, 'rmse': np.float64(0.0035975373707947066), 'r2': -1.5751724243164062, 'direction_accuracy': 0.5002008032128514}\n"
     ]
    }
   ],
   "source": [
    "#run a set of preds on test data\n",
    "preds = predict(TrainedModel, testLoader)\n",
    "#evaluate the model performance based on preds\n",
    "eval_results = eval_model_performance(y_pred=preds, y_actual=testLoader.dataset.y, feature_names=feature_columns, target_name=dataPARAMS['target_column'])\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd073b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
